/**
 * Gemini AI SDK Initialization and Utilities
 * 
 * This module provides a centralized way to interact with Google's Gemini AI.
 * Supports text generation, multimodal input (images), and streaming responses.
 */

import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from '@google/generative-ai';

// Initialize with API key
const apiKey = process.env.GEMINI_API_KEY || '';
const genAI = new GoogleGenerativeAI(apiKey);

// Safety settings - balanced for educational content
const safetySettings = [
    {
        category: HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
        category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
        category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    {
        category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
];

// Default generation config
const defaultConfig = {
    temperature: 0.7,
    topK: 40,
    topP: 0.95,
    maxOutputTokens: 1024,
};

// System instruction for AIM Buddy
export const AIM_BUDDY_INSTRUCTION = `You are Padhaku AI, a friendly and supportive AI study companion for school students. You already have access to the student‚Äôs class level and learning ability, and you must adapt your explanations accordingly.

Your purpose is to make learning simple, engaging, and stress-free while also helping students perform better in exams.

üé≠ Personality & Tone
- Speak in a warm, friendly, and encouraging tone
- Sound like a favorite teacher mixed with a helpful senior
- Never sound robotic, strict, or judgmental
- Make the student feel safe asking doubts repeatedly
- Always maintain: patience, positivity, respect
- **Name Usage**: Do NOT use the user's name in every sentence. Once at the start is enough. Use "yaar", "buddy", or "dost" occasionally instead.

üìò Teaching Method
When explaining any topic:
- Start with very simple language
- Break the concept into small steps
- Then give deeper explanation only if needed
- Use: bullet points, short paragraphs, clear structure

üåç Examples Rule
Whenever possible, use relatable examples from:
- daily life
- school situations
- games
- common real-world experiences
Avoid abstract textbook-only explanations.

‚ùì Doubt Solving Format
When a student asks a question:
1. Give a direct answer
2. Explain in simple words
3. Provide an example
4. End with a gentle check like: ‚ÄúDoes this make sense?‚Äù or ‚ÄúWant another example?‚Äù

üíõ Emotional Support Logic
If the student says they are weak, confused, or frustrated:
- Respond with encouragement such as: "Learning takes time and that is okay", "Many students find this topic tricky", "We will go step by step"
- Never criticize, shame, or show impatience.

üèÜ Motivation Rules
- Praise effort, not just correct answers
- Encourage improvement and curiosity
- Make the student feel progress is possible

üìö Exam Support Mode
While teaching, also:
- Highlight important exam points
- Mention key terms, formulas, or definitions
- Help structure answers in proper exam format

üîÑ Adaptation Rule
Adjust explanation depth based on student level:
- Weak student ‚Üí simpler language, slower pace
- Average student ‚Üí normal explanation + examples
- Strong student ‚Üí deeper concept + extra insights

üö´ Safety & Boundaries
- If the student asks about harmful, illegal, or adult topics: Politely redirect to studies with a calm response like: ‚ÄúLet‚Äôs stay focused on your learning. Which subject do you need help with?‚Äù
- Do not engage in unsafe discussions.

üéØ Final Objective
Make the student feel:
- comfortable asking questions
- confident about learning
- less afraid of difficult subjects

CRITICAL TECH GUIDELINES:
1. **Accuracy First**: NEVER hallucinate or guess specific data like Exam Dates, Exact Syllabus Chapters, or Cutoffs. If unsure, tell the user to check official sources.
2. **Formatting**: Use Markdown extensively (**Bold** for key terms, *Bullet points* for lists, \`Code blocks\` for formulas).
3. **Conciseness**: Keep answers punchy. Avoid walls of text.
`;

/**
 * Get the text-only Gemini model
 * Using gemini-2.5-flash for best performance (250K TPM)
 */
/**
 * Get the text-only Gemini model
 * Using gemini-1.5-flash (User requested "Flash")
 */
export function getTextModel() {
    return genAI.getGenerativeModel({
        model: 'gemini-flash-latest',
        safetySettings,
        generationConfig: defaultConfig,
        systemInstruction: AIM_BUDDY_INSTRUCTION,
    });
}

/**
 * Get the multimodal Gemini model (for images)
 * Using gemini-1.5-flash
 */
export function getMultimodalModel() {
    return genAI.getGenerativeModel({
        model: 'gemini-flash-latest',
        safetySettings,
        generationConfig: defaultConfig,
        systemInstruction: AIM_BUDDY_INSTRUCTION,
    });
}

/**
 * Simple text generation (non-streaming)
 */
export async function generateText(prompt: string): Promise<string> {
    const model = getTextModel();
    const result = await model.generateContent(prompt);
    return result.response.text();
}

/**
 * Chat generation with history
 */
export async function generateChatResponse(
    message: string,
    history: Array<{ role: 'user' | 'model'; parts: Array<{ text: string }> }> = []
): Promise<string> {
    const model = getTextModel();
    const chat = model.startChat({ history });
    const result = await chat.sendMessage(message);
    return result.response.text();
}

/**
 * Streaming text generation
 */
export async function* streamText(prompt: string): AsyncGenerator<string> {
    const model = getTextModel();
    const result = await model.generateContentStream(prompt);

    for await (const chunk of result.stream) {
        const text = chunk.text();
        if (text) yield text;
    }
}

/**
 * Streaming chat generation with history
 */
export async function* streamChatResponse(
    message: string,
    history: Array<{ role: 'user' | 'model'; parts: Array<{ text: string }> }> = []
): AsyncGenerator<string> {
    const model = getTextModel();
    const chat = model.startChat({ history });
    const result = await chat.sendMessageStream(message);

    for await (const chunk of result.stream) {
        const text = chunk.text();
        if (text) yield text;
    }
}

/**
 * Multimodal generation (text + image)
 */
export async function generateWithImage(
    prompt: string,
    imageBase64: string,
    mimeType: string = 'image/jpeg'
): Promise<string> {
    const model = getMultimodalModel();

    const result = await model.generateContent([
        prompt,
        {
            inlineData: {
                data: imageBase64,
                mimeType,
            },
        },
    ]);

    return result.response.text();
}

/**
 * Check if Gemini is configured
 */
export function isGeminiConfigured(): boolean {
    return !!apiKey && apiKey.length > 0;
}

export { genAI };
